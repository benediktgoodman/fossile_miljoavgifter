{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9091aa6c",
   "metadata": {},
   "source": [
    "# Demo-notebook for bruk av funksjoner til å regne ut energiavgifter tilknyttet fossilt brensel\n",
    "\n",
    "*Forfatter: Benedikt Goodman*\n",
    "\n",
    "I denne teksten vil kun essensen av hva hvert objekt og metode gjør beskrives. Dersom detaljert informasjon om et objekt trenges kan man skrive **help(objektnavn.metodenavn)** eller **help(funksjonsnavn)** for å få tak i informasjonen om hva objektene/funksjonene gjør og hva de godtar av input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a09f9-fa06-4908-ab60-2f6ded46bc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Change directory until find project root\n",
    "notebook_path = os.getcwd()\n",
    "while \"pyproject.toml\" not in os.listdir():\n",
    "    os.chdir(\"../\")\n",
    "\n",
    "# Import math modules\n",
    "from src.functions.main_program_functions import divider, multiplier, proportion_func, make_sum_column, diff_maker\n",
    "# Import data utils\n",
    "from src.functions.main_program_functions import merge_func, subsetter, multi_subsetter, filename_removal_func, associate_codes, rounding_error_dealer, column_tidy_func\n",
    "# Import verifier functions\n",
    "from src.functions.main_program_functions import data_integrity_checker, unntak_filler\n",
    "\n",
    "# Import helperfunction for making mineral oils\n",
    "from src.functions.main_program_functions import calculate_mineral_oil\n",
    "\n",
    "# Import data import assets\n",
    "from src.functions.import_class import DataImporter\n",
    "from src.functions.metadata_generator import FolderSearcher\n",
    "\n",
    "# Import export helpers\n",
    "from src.functions.export_helpers import batch_exporter\n",
    "\n",
    "# Import testfuncs\n",
    "from tests.main_program_functions_testing import missing_nrnaaring_tester\n",
    "\n",
    "# Reset current working directory after local imports\n",
    "os.chdir(notebook_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab8d2d",
   "metadata": {},
   "source": [
    "## Om objektene som er laget for dette produksjonsløpet\n",
    "\n",
    "### Identifikasjon av data ved hjelp av FolderSearcher\n",
    "\n",
    "#### Instansiering av objektet\n",
    "Brukeren navigerer til filstien (path) hvor dataene for beregningsopplegget ligger. Deretter definerer hen en liste med datasett (dataset_list) som skal importereres. Denne listen brukes av FolderSearcher som leter etter mapper på lokasjonen til path som matcher listen. Brukeren kan også anngi datatypen objektet skal lete etter (datatype).\n",
    "\n",
    "FolderSearcher spør også om start og sluttperiode for import av data. For at denne funksjonen skal fungere må folderne den importerer data fra har år som navn. Objektet tar ikke hensyn til om det er år som mangler i filhirearkiet.\n",
    "\n",
    "#### Om metodene til FolderSearcher\n",
    "- *.generate_metadata()* lager FolderSearcher en dataframe filstier, filnavn og hvilken i hvilken mappe filene finnes \n",
    "- *.subset_datasets()* beholder kun verdiene (keep_vals=[]) i angitt gruppe (groups=[]). I dette tilfellet fjerner den alle forekomster av energiregnskapet unntatt 2021 fra metadataene. Disse må være lagret i lister, ellers gir objektet feilemelding. Dersom filtreringen ikke inntreffer kan det være fordi keep_vals argumentet er av feil datatype. Filtreringen godtar nemlig strings, ints, floats og det meste annet.\n",
    "- *.output_df()* spytter ut dataframen objektet har laget.\n",
    "\n",
    "Ved å dele opp innlesningen av filinformasjon så kan brukeren selv velge hvilke filer som skal importeres da alle pandas sine funksjoner fungerer på dataframen man får ut. Dermed kan man velge ut subsets av data man vil importere dersom man ser at FileSearcher har vært for generøs med hva den har funnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d80f933-c940-4a9a-96b7-bb87e1e3da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definer filsti hvor subfoldere med data finnes\n",
    "path = '/ssb/stamme02/nasjregn' + '/miljoregnskaper/skatter/arkiv/'\n",
    "\n",
    "# Skriv hvilke datasett du vil at objektet skal lete etter\n",
    "datasets = [\n",
    "    'innbetalte_avgifter',\n",
    "    'kvotepliktige',\n",
    "    'omkoding_nr',\n",
    "    'satser',\n",
    "    'unntakskatalog',\n",
    "    'energiregnskapet']\n",
    "\n",
    "# FolderSearcher lager en dataframe basert på input og hva den funner.\n",
    "# I denne dataframen finnes alt som trengs av DataImporter for å importere data\n",
    "# og kategorisere dem. Dette er en helt normal dataframe så brukeren kan endre\n",
    "# på og filtrere som hen har lyst til*\n",
    "metadata_df = (FolderSearcher(path, datatype='sas7bdat', dataset_list=datasets)\n",
    "               .generate_metadata()\n",
    "               .subset_energiregnskapet()\n",
    "               .output_df()\n",
    "              )\n",
    "\n",
    "# Vis dataframe\n",
    "metadata_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5efb0c-8ff1-43d6-b316-bc170f77bfea",
   "metadata": {},
   "source": [
    "Alle tilgjengelige metoder har medhørende dokumentasjon som er lett tilgjengelig via pythons help() funksjonalitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6723c7-4d1a-4202-a1a5-0fa69f573519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hvordan vise dokumentasjonen til en metode i et objekt\n",
    "#help(FolderSearcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ae3c0-dd06-47af-916a-266061de7b84",
   "metadata": {},
   "source": [
    "### Import av data ved hjelp av DataImporter\n",
    "\n",
    "DataImporter leser inn dataframen med metadata og bruker så denne til å lese inn og kategorisere dataene etter brukerangitte kategorier. Dataene lagres i en **dictionary**. Den bruker kun metadata_df som input argument når den instansieres. Objektet tar inn en hvilken som helst dataframe, men metodene som tilhører objektet antar at 3 kolonner eksisterer i dataframe. Dette er kolonner med:\n",
    "- komplett filsti til datafilene som skal importeres\n",
    "- fullt filnavn\n",
    "- hvilken mappe filstiene ligger i\n",
    "\n",
    "Objektet antar foreløpig implisitt at dataene den leter i ligger i undermapper.\n",
    "\n",
    "#### Om metodene til DataImporter\n",
    "- simple_import() importerer et sett med filer basert på en kolonne med filstier i en dataframe og returnerer en dictionary hvor datasettene ligger sortert per mappe de leses inn fra. Metoden har en mengde input argumenter som gjør den fleksibel i bruk. På det minste trenger den kun hvilken datatype den skal lese inn (filetype). For øvrige input argumenter skriv help(DataImporter.simple_import).\n",
    "- add_years() legger til mappenavnet datasettet finnes til som variabel i datasettet. Dersom navnet er et år vil datasettene nå inneholde hvilken årgang de er fra.\n",
    "- categorise_data() sorterer de importerte dataene basert på mappetilhørlighet, filnavn og en liste med brukerangitte kategorier. For å garantere at hver fil havner i riktig kategori er beste å bruke samme liste man brukte for å søke etter data.\n",
    "    - Dersom man har mange årganger av samme datasett lagret i mange ulike subfoldere så vil **denne reorganiseringen gjøre det mulig å beregne for alle år av gangen da metoden limer alle datasett av samme kategori til en dataframe**. Hoveddtanken bak dette er å gjøre tilbakeregninger enkelt.\n",
    "- year_duplicate_tidy_func() ser etter duplikatverdier i to kolonner og sletter kolonne nummer to dersom nummer en allerede finnes i datasettet. Dette er for å rette opp i der hvor add_years() er for naiv i å legge til år (f.eks for et datasett fra en folder med årsnavn men som inneholder flere årganger)\n",
    "- write_data() skriver ut enten den opprinnelige dictionarien importert fra simple_import() (dersom man er usikker på om andre metoder har tullet til dataene kan dette f.eks være bra for debugging) eller den reorganiserte dictionarien laget av categorise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99d7a8-f85c-4bc8-8263-253d9e787edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laste inn data og få det på riktig form\n",
    "data = (DataImporter(metadata_df)\n",
    "        .simple_import(filetype='sas7bdat') \n",
    "        .add_years()\n",
    "        .categorise_data(dataset_list=datasets)\n",
    "        .year_duplicate_tidy_func(dupl_col1='aar', dupl_col2='aar_added')\n",
    "        .sort_df(sort_by=['aar', 'produktkode'])\n",
    "        .write_data(output_object='sorted_df'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f1655-a96f-418f-a32a-bac63178e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['energiregnskapet'] = calculate_mineral_oil(data['energiregnskapet'])\n",
    "\n",
    "data['energiregnskapet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8ae3b-0ead-4a6f-b277-0ca76da87090",
   "metadata": {},
   "source": [
    "## Eksempel på bruk av funksjonene i main_program_functions.py for å lage produksjonsløpet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df27add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ta ut aktuelle subset av kildedata\n",
    "jet_forb = subsetter(data, key='energiregnskapet', var='produktkode',\n",
    "                     value='EP04661')\n",
    "\n",
    "jet_unntak = subsetter(data, key='unntakskatalog', var='produktkode',\n",
    "                       value='EP04661')\n",
    "\n",
    "avgifter_jetparafin = subsetter(data, key='innbetalte_avgifter',\n",
    "                                var='produktkode', value='EP04661')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a2cfe-93f6-45d9-b98c-49c44280d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgifter_jetparafin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd9182-6ed0-44ce-a236-09167052acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of multi_subsetter\n",
    "multi_subsetter(data, key='innbetalte_avgifter', ytart='41364', produktkode='EP030')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c617fc",
   "metadata": {},
   "source": [
    "Pandas har en funksjon som tillater at man kan lage en modulær pipeline slik som man gjør i R med %>% operatoren. Dette gjør at man kan bygge enkeltfunksjoner som gjør en del av jobben, og så kan man koble dem sammen slik at de til sammen kjører hele opplegget for en gitt energivare. Dette gjør at man ender opp med et modulært system hvor en selv kan sette rekkefølgen på funksjonene man bruker og hvor man selv står fritt til å definere input-argumenter for hvert trinn.\n",
    "\n",
    "Denne metoden heter .pipe()\n",
    "\n",
    "Kort sagt så tillater den at man kan bruke funksjoner man har brukt på egen hånd på dataframes og den lar seg kjede som alle andre pandas metoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d2d528",
   "metadata": {},
   "source": [
    "### Eksempel på hvordan funksjonene kan settes sammen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c097ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "jetparafin = (\n",
    "    # Joins unntaks katalog onto forbruk by aar and næringskode\n",
    "    merge_func(jet_forb, jet_unntak,\n",
    "               subset_columns_r=['aar', 'naaringskode', 'unntak', 'ytart'],  # This argument selects columns \n",
    "               join_on=['aar', 'naaringskode'],\n",
    "               join_method='left',\n",
    "              )\n",
    "    # removes filename from dataframe column\n",
    "    #.pipe(filename_removal_func)\n",
    "    \n",
    "    # Fills in unntakskatalog\n",
    "    .pipe(unntak_filler)\n",
    "    \n",
    "    # Calculates avgiftsbelagt mengde\n",
    "    .pipe(multiplier, X='mengde', Y='unntak', new_col='avgiftsbelagt_mengde')\n",
    "    \n",
    "    # Calculates total avgiftsbelagt mengde\n",
    "    .pipe(make_sum_column,\n",
    "          group='aar',\n",
    "          target_col='avgiftsbelagt_mengde',\n",
    "          new_col='total_avgiftsbelagt_mengde')\n",
    "    \n",
    "    # Merges avgifter for jetparafin onto main dataframe\n",
    "    .pipe(merge_func, avgifter_jetparafin,\n",
    "          subset_columns_r=['aar', 'produktkode', 'total_avgift_kroner'],\n",
    "          join_on=['aar', 'produktkode'])\n",
    "    \n",
    "    # Calculates avgiftsbelagt mengde\n",
    "    .pipe(proportion_func,\n",
    "          X='avgiftsbelagt_mengde',\n",
    "          Y='total_avgiftsbelagt_mengde',\n",
    "          Z='total_avgift_kroner',\n",
    "          new_col='est_avgift_kroner')\n",
    "    \n",
    "    # Attach NR codes from omkoding to main dataframe\n",
    "    .pipe(associate_codes,\n",
    "         df_codes=data['omkoding_nr'],\n",
    "         ind_code_col='naaringskode',\n",
    "         nr_code_col = 'nr_naaring',\n",
    "         prod_name_col = 'produkt_tekst',\n",
    "         prod_name = 'Jetparafin')\n",
    "    \n",
    "    # Checks and attributes diff column to est_avgifter_kroner\n",
    "    .pipe(rounding_error_dealer)\n",
    "    \n",
    "    # Checks for missing nr_codes where est_avgifter_kroner != 0\n",
    "    # Shows rows of the df if codes are missing\n",
    "    .pipe(missing_nrnaaring_tester)\n",
    "\n",
    "    # Reshapes an aggregates main df to nr-code level\n",
    "    .pipe(column_tidy_func,\n",
    "        keep_cols=['ytart', 'produkt_tekst', 'aar', 'nr_naaring'],\n",
    "        avgift_col='est_avgift_kroner')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c85735-7fd3-4091-b6d3-6585b423a905",
   "metadata": {},
   "source": [
    "Når alle datasettettene er kommet på formen over kan de limes sammen vi pd.concat og deretter exporteres med batch_exporter funksjonen.\n",
    "\n",
    "Denne funksjonen oppretter mapper basert på hvert enkelt år i datasettet og eksporterer data fra samme år i samme mappe som ett enkelt datasett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21244024-64d6-47fd-bf5e-8d12170b7a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_df = pd.concat([jetparafin, autodiesel etc...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f2073-93b6-4a33-b727-57bec3d0517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(batch_exporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe1b89-c851-4ea9-b5df-bf850112e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exports datsets into subfolders\n",
    "batch_exporter(jetparafin, year_col='aar', \n",
    "               export_path='../output_data', # can also be path to anywhere else on linux\n",
    "               prefix='jet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fossile_miljoavgifter",
   "language": "python",
   "name": "fossile_miljoavgifter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
